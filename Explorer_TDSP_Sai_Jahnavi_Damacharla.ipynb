{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaiJahnaviD/TDSP_NewYork_ColumbiaUniversity/blob/main/Explorer_TDSP_Sai_Jahnavi_Damacharla.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸš— **Welcome to the <font color='crimson'>** **Explorer Transportation Data Science Project! ðŸš—**</font>\n",
        " Hosted by the [Northeast Big Data Innovation Hub](https://nebigdatahub.org/about) & [National Student Data Corps](https://nebigdatahub.org/nsdc), in collaboration with the [U.S. Department of Transportation Federal Highway Administration](https://highways.dot.gov/).\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "4XMQbpf49Iwp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKnVUiwQZPdq"
      },
      "source": [
        "## <font color='crimson'>**Project Information and Background:**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Project Description:**\n",
        "\n",
        "By participating in this project, you are joining a\n",
        "community of transportation data science learners interested in making roads safer for vulnerable road users.\n",
        "\n",
        "The Explorer TDSP has six Milestones, including guided transportation research into a community of interest. Each Milestone can take 1-5 hours, or less, depending on your level of experience.\n",
        "\n",
        "To learn more about this project, including key highlights, incentives, and important links, [review the TDSP Webpage here](https://nebigdatahub.org/nsdc/tdsp/)!"
      ],
      "metadata": {
        "id": "BybRYF48QePA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='crimson'>**How to Get Started:**</font>\n"
      ],
      "metadata": {
        "id": "iYsruLb8CH8a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to work within this Google Colab Notebook, **please start by clicking on \"File\" in the top left corner of your notebook, and then \"Save a copy in Drive.\" Rename the file to \"Explorer TDSP - Your Full Name.\"** This will save a copy of the notebook in your personal Google Drive.\n",
        "\n",
        "You may now begin!\n",
        "\n"
      ],
      "metadata": {
        "id": "9qWTN6tkQiKl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mty7kOOZPdq"
      },
      "source": [
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='crimson'>**A Quick Introduction to Google Colab**</font>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Yog3c5lwIX0p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read below for a Google Colab QuickStart:\n",
        "- Google Colab is a Python Notebook environment built by Google that's free for all.\n",
        "- Colab Notebooks are made up of cells; cells can be either *text* or *code* cells. You can click the +code or +text button at the top of the Notebook to create a new cell.\n",
        "- Text cells use a format called [Markdown](https://www.markdownguide.org/getting-started/). Knowledge of Markdown is not required for this project. However, if you'd like to learn more, [check out this Cheatsheet!](https://www.markdownguide.org/cheat-sheet/)\n",
        "- Python code is executed in *code* cells. When you want to run your code, hover your cursor over the square brackets in the top left corner of your code cell. You'll notice a play button pop up! (â–¶) Click the play button to run the code in that cell. Code cells run one at a time.\n",
        "- The memory shared across your notebook is called the *Runtime*. You can think of a Runtime as a \"code session\" where everything you create and execute is temporarily stored.\n",
        "- Runtimes will persist for a short period of time, so you are safe if you need to refresh the page, but Google will shutdown a Runtime after enough time has passed. Everything that you have printed out will remain within your Notebook even if the runtime is disconnected.\n",
        "\n",
        "If this is your first time using Google Colab, we highly recommend reviewing the [NSDC's *Using Google Colab Guide*](https://nebigdatahub.org/wp-content/uploads/2023/04/NSDC-Data-Science-Projects-Introduction-Using-Google-Colab.pdf) before continuing. For a more comprehensive guide, see [Colab's *Welcome To Colaboratory* walkthrough.](https://colab.research.google.com/github/prites18/NoteNote/blob/master/Welcome_To_Colaboratory.ipynb)"
      ],
      "metadata": {
        "id": "WHba4I24yBt8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='crimson'>**An Introduction to Python Programming**</font>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UnE1MXoBJ1ST"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python is a programming language often used to analyze data.\n",
        "\n",
        "Python is open-source, which means it's free to use and distribute, even for commercial purposes. Python's versatility allows it to be used for web development, data visualization, artificial intelligence, scientific computing, and more.\n",
        "\n",
        "Python's extensive standard library, along with its powerful third-party packages, enable developers and data scientists to perform a vast array of tasks.\n",
        "\n",
        "For those looking to dive deeper into Python, here are some valuable resources:\n",
        "- [The Official Python Documentation](https://docs.python.org/3/) â€“ Offers comprehensive guides and reference materials for Python leaners.\n",
        "- [Real Python](https://realpython.com/) â€“ Provides tutorials and articles for Python developers of all skill levels.\n",
        "- [PyCon](https://pycon.org/) â€“ The largest annual gathering for the Python community, which is useful for learning from experts and discovering the latest developments in the Python ecosystem.\n",
        "- [Python for Everybody](https://www.py4e.com/) â€“ A book and website by Dr. Charles Severance that offers a free course on Python for beginners."
      ],
      "metadata": {
        "id": "0iM6cO7DL6XS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's review some essential Python Functions!**\n",
        "\n",
        "Here are some key functions you'll frequently encounter:\n",
        "\n",
        "1. **`head()`**: This function is crucial for getting a quick overview of your dataset. By default, it returns the first five rows, offering a snapshot of your data's structure and values.\n",
        "\n",
        "2. **`describe()`**: This provides a summary of the statistical characteristics of your dataset. It's particularly useful for gaining insights into the distribution, mean, standard deviation, and range of numerical columns.\n",
        "\n",
        "3. **`sum()`**: This calculates the total sum of a column or a series of numbers, proving essential for quick calculations and aggregations in data analysis.\n",
        "\n",
        "4. **`isnull()`**: This helps identify missing or null values in your dataset, allowing for effective data cleaning and preprocessing.\n",
        "\n",
        "5. **`value_counts()`**: Understanding the frequency of various values in your dataset is a common task in data science. The `value_counts()` function makes this easy by counting the occurrence of each unique value in a column.\n",
        "\n",
        "Now that you've reviewed these important concepts, let's dive in to the project!"
      ],
      "metadata": {
        "id": "Z9WPv-vPP3FC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQpujHnvZPdr"
      },
      "source": [
        "## <font color='crimson'>**Milestone #1 - Data Preparation**</font>\n",
        "GOAL: The main goal of this milestone is to set up your environment, install the required packages, learn how to access data and do some basic exploratory data analysis.\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmouMnaaZPdr"
      },
      "source": [
        "**Step 1:** Setting up libraries and installing packages\n",
        "\n",
        "A **library** is a collection of code that you can use in your programs, while a **package** is a folder that contains libraries or other packages, organized for easy use.\n",
        "\n",
        "To install a library, we'll use the following format:\n",
        "```python\n",
        " import <library name> as <shortname>\n",
        "```\n",
        "We use a *short name* since it is easier to refer to the package to access functions and also to refer to subpackages within the library. Think of it as a nickname for easier reference!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "le2dKHwnZPds"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import folium"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qy1yhZqNZPdt"
      },
      "source": [
        "These are the libraries that will help us throughout this project. We invite you to research each library for a better understanding.\n",
        "\n",
        "We encourage you to read more about the important and most commonly used libraries like Pandas, Matplotlib, and Seaborn and write a few lines in your own words about what they do. [You may use the Data Science Resource Repository (DSRR) to find resources to get started!](https://nebigdatahub.org/nsdc/data-science-resource-repository/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TO DO:** Write a few lines about what each library does:\n",
        "\n",
        "\n",
        "> * Pandas: Pandas is a python library, used for handling structured data, mostly used for data analysis and initial steps. It is very useful in providing data structures and functions that make it easy to work with datasets, such as tables, time series, and matrices.\n",
        "\n",
        "> * Matplotlib: Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python. It is a powerful tool for data visualization, allowing you to generate a wide variety of plots and charts, such as: Line plots, Scatter plots, Bar charts, Histograms, Pie charts, Box plots, and 3D plots, etc.\n",
        "\n",
        "> * Seaborn: Seaborn is a Python data visualization library based on Matplotlib. It provides a high-level interface for creating informative and attractive statistical graphics. Seaborn comes with built-in themes and color palettes to enhance the appearance of plots and makes it easy to create complex visualizations like heatmaps, box plots, and pair plots with minimal code.\n"
      ],
      "metadata": {
        "id": "BbzAwqe-cEgI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dInyzwncZPdt"
      },
      "source": [
        "**Step 2:** Letâ€™s access our data. We will be using the [NYC OpenData Motor Vehicle Collisions - Crashes dataset](https://data.cityofnewyork.us/Public-Safety/Motor-Vehicle-Collisions-Crashes/h9gi-nx95). According to NYC Open Data, \"each row represents a crash event. The Motor Vehicle Collisions data tables contain information from all police reported motor vehicle collisions in NYC.\" If you need a reminder on how to upload your dataset, [please review helpful hints here.](https://nebigdatahub.org/wp-content/uploads/2023/04/NSDC-Data-Science-Projects-Introduction-Using-Google-Colab.pdf)\n",
        "\n",
        "Since this is a large dataset, we highly recommend that you upload your data by [mounting your Google Drive](https://colab.research.google.com/notebooks/io.ipynb#scrollTo=u22w3BFiOveA).\n",
        "\n",
        "To mount your Google Drive, begin by finding the folder icon on the left side of your screen. When you click on this folder icon, you will open the Files window. Click on the icon at the top of the Files window that says \"Mount Drive\" as you hover over it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lbMS5rPxUa6-",
        "outputId": "f54dd954-af90-4811-9043-a5e496b6ebbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "mount failed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         )\n\u001b[0;32m--> 277\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we will read the data using the `pd.read_csv` function.\n",
        "Ensure that you've downloaded the dataset from NYC OpenData, and uploaded the dataset to your Google Drive.\n",
        "\n"
      ],
      "metadata": {
        "id": "vi2OnWfcJpDW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hint: Your data's file path describes the location of where your data lives. To locate your data's file path, click on the folder/file-shaped icon on the left side of the Notebook. You'll notice a folder labeled \"drive.\" Search for your Motor Vehicle Collisions Dataset within that folder. Right click on your Dataset to \"copy path.\" Paste that path below."
      ],
      "metadata": {
        "id": "ODWydXCBaURB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBDt0Qvzndex"
      },
      "outputs": [],
      "source": [
        "# TODO: Read the data using pandas read_csv function\n",
        "#data = pd.read_csv(\"/content/drive/MyDrive/Motor_Vehicle_Collisions_-_Crashes_20250113.csv\")\n",
        "#data = pd.read_csv(\"/content/drive/MyDrive/Motor_Vehicle_Collisions_-_Crashes_20250113.csv\", dtype={\"column_name\": str})\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Motor_Vehicle_Collisions_-_Crashes_20250113.csv\", low_memory=False)\n",
        "print(data)\n",
        "print(data.columns.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhFDTTsSZPd4"
      },
      "source": [
        "**Step 3:** Let's see what the data looks like. We can use the `head` function which returns the first 5 rows of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24duiI4RpNDN"
      },
      "outputs": [],
      "source": [
        "# TODO: Print the first 5 rows of the data using head function of pandas\n",
        "data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfzpsKR2BIFy"
      },
      "outputs": [],
      "source": [
        "# TODO: Describe the data using the describe function of pandas\n",
        "desc_stats = data.describe()\n",
        "desc_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The information above is currently formatted in scientific notation. Need a refresher? [Review how to analyze and convert to and from scientific notation here!](https://www.mathsisfun.com/numbers/scientific-notation.html)\n",
        "\n",
        "1. Latitude & Longitude: The latitude and longitude indicate where the crashes are occurring. However, there are some data points with latitude and longitude values of 0, which is likely due to missing or inaccurate data.\n",
        "\n",
        "2. Number of Persons Injured: On average, each crash has around 0.305 injuries. The maximum number of injuries in a single crash is 43.\n",
        "\n",
        "3. Number of Persons Killed: Fatalities are rare, with an average of 0.00146 deaths per crash. The maximum number of deaths in one crash is 8.\n",
        "\n",
        "4. Number of Pedestrians, Cyclists, and Motorists Injured/Killed: These columns provide a breakdown of the injuries and fatalities by type of individual involved.\n",
        "\n",
        "5. Collision ID: This is a unique identifier for each crash."
      ],
      "metadata": {
        "id": "TS4P8nxXeE67"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "r60jw9F1HHKU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3NohCaoZPd6"
      },
      "source": [
        "##<font color='crimson'> **Milestone #2 - Data Ethics, Pre-Processing, and Exploration** </font>\n",
        "GOAL: The main goal of this milestone is to assess the dataset, find missing values, and decide what to do with those missing data points."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksvQoYszUTyP"
      },
      "source": [
        "**Step 1:**\n",
        "Before we begin assessing our data for missing values, it is important that we understand the ethical implications surrounding data processing. To best prepare yourself for this module, review one or more of the following resources:\n",
        "- [Data Science Ethics Flashcard Video Series](https://youtube.com/playlist?list=PLNs9ZO9jGtUB7XTjXy-ttoo2QSLld9SrV&feature=shared)\n",
        "- [What Do I Need to Understand about Data Ethics?](https://www.youtube.com/watch?v=Efy8htCDueE)\n",
        "-[Introduction to Data Cleaning](https://www.youtube.com/watch?v=t8WkoGLkdTk)\n",
        "\n",
        "**TO DO:** Based on the resources above and outside knowledge, what are some potential bias issues related to the availability of data from well-resourced communities as compared to under-resourced communities? How might bias show up in our dataset?\n",
        "\n",
        "> Answer here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1uBbf33ZPd6"
      },
      "source": [
        "**Step 2:**\n",
        "Check the dataset for missing values.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Leverage the isnull() and sum() functions to find the number of missing values in each column\n",
        "missing_values = data.isnull().sum()\n",
        "\n",
        "#TODO: Turn the missing value counts into percentages\n",
        "missing_values_percentage = (missing_values / len(data)) * 100\n",
        "\n",
        "# Display the missing values percentage\n",
        "print(\"The missing values percentage : \")\n",
        "print(missing_values_percentage)\n",
        "\n",
        "#TODO: Return counts and percentages of missing values in each column\n",
        "missing_data = pd.DataFrame({'Missing Values': missing_values, 'Percentage (%)': missing_values_percentage})\n",
        "missing_data_sorted = missing_data.sort_values(by='Percentage (%)', ascending=False)\n",
        "print(\"The missing data sorted : \")\n",
        "print(missing_data_sorted)"
      ],
      "metadata": {
        "id": "D5UTO86_jZkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's an overview of the missing values in the dataset:\n",
        "\n",
        "Columns like VEHICLE TYPE CODE 5, CONTRIBUTING FACTOR VEHICLE 5, VEHICLE TYPE CODE 4, and so on have a high percentage of missing values. This is expected since not all crashes involve multiple vehicles or factors.\n",
        "\n",
        "OFF STREET NAME and CROSS STREET NAME have significant missing values. This could be due to crashes occurring in locations where these details aren't applicable or weren't recorded.\n",
        "\n",
        "ZIP CODE, BOROUGH, and ON STREET NAME also have missing values. This might be due to incomplete data entry or crashes occurring in areas where these specifics aren't easily determinable.\n",
        "\n",
        "LOCATION, LATITUDE, and LONGITUDE have the same count of missing values, indicating that when one is missing, the others are likely missing as well."
      ],
      "metadata": {
        "id": "BnkgVJLpkTyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3:** Create a bar chart to display the top 10 contributing factors (e.g. backing up unsafely, unsafe lane changing, etc.) to crashes within the dataset."
      ],
      "metadata": {
        "id": "3oi7hU-YxKEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Plot a Bar Chart\n",
        "\n",
        "top_factors = data['CONTRIBUTING FACTOR VEHICLE 1'].value_counts().head(10)\n",
        "\n",
        "plt.figure(figsize=(12, 7))\n",
        "# Plotting the top contributing factors\n",
        "sns.barplot(x=top_factors.index, y=top_factors.values, palette=\"magma\")\n",
        "plt.title('Top 10 Contributing Factors to Crashes', fontsize=16)\n",
        "plt.xlabel('Contributing Factors', fontsize=14)\n",
        "plt.ylabel('Number of Crashes', fontsize=14)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sOAZEE5jxxKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TO DO:** Besides for \"Unspecified,\" what are the top 3 contributing factors that cause the most crashes?\n",
        "\n",
        "> *  Driver Inattention/Distraction\n",
        "> *  Failure to Yield Right-of-Way\n",
        "> *  Following too Closely\n"
      ],
      "metadata": {
        "id": "f8XmI5o7d2Ii"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TO DO:** What recommendations would you make to new and current drivers after assessing the above data?\n",
        "\n",
        "> *   Driver should be very cautious and careful while driving. They should not go very close to the vehicles on the road. They should remember signals, timings and ways that they are going to travel.\n",
        "They should be very attentive and ready to save when any accident approaches.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KJNcc4SIeVUO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4:** Now, let's create another bar chart to determine which vehicle types were involved in the most crashes."
      ],
      "metadata": {
        "id": "t7Mxj6IJyf8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Determine the top vehicle types involved in crashes\n",
        "top_vehicle_types = data['VEHICLE TYPE CODE 1'].value_counts().head(10)\n",
        "\n",
        "# Plotting the top vehicle types\n",
        "plt.figure(figsize=(12, 7))\n",
        "sns.barplot(x=top_vehicle_types.index, y=top_vehicle_types.values, palette=\"cividis\")\n",
        "plt.title('Top 10 Vehicle Types Involved in Crashes', fontsize=16)\n",
        "plt.xlabel('Vehicle Type', fontsize=14)\n",
        "plt.ylabel('Number of Crashes', fontsize=14)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "iCQq3tvAzCVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TO DO:** What are the top 3 vehicles that were most involved in crashes?\n",
        "\n",
        "\n",
        "> *   Sedan\n",
        "> *   Station Wagon/Sport Utility Vehicle\n",
        "> *   Passenger Vehicle\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GDZX7-jvfAkW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TO DO:** Why do you think that \"Sedan[s],\" \"Station Wagon[s],\" and \"Passenger Vehicle[s]\" are involved in a larger number of crashes, injuries, and deaths when compared to the rest of the vehicles? (Think outside the box!)\n",
        "\n",
        "\n",
        ">1. **High Prevalence**: Sedans, station wagons, and passenger vehicles are the most common on roads, increasing their exposure to accidents.  \n",
        "2. **Urban Usage**: These vehicles are widely used in traffic-dense urban areas, where the risk of collisions is higher.  \n",
        "3. **Diverse Drivers**: New and elderly drivers often use these vehicles, both groups being more prone to accidents due to inexperience or health limitations.  \n",
        "4. **Family and Trips**: Frequent use for family transportation and long trips adds distractions and fatigue, contributing to crashes.  \n",
        "5. **Reporting Bias**: Crashes involving these vehicles are more likely to be reported due to insurance and broader classification categories.  \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wVDx-bhefg_3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TO DO:** Review the x-axis of the bar chart you created above. </br>\n",
        "1) What do you notice? </br>\n",
        "2) What would you recommend we do to improve the bar chart, based on the x-axis (horizontal axis) and why? </br>\n",
        "3) What recommendation would you make to those who are collecting and/or inputting data into this dataset?\n",
        "\n",
        "\n",
        ">### 1) **What do you notice?**  \n",
        "- The x-axis contains the names of vehicle types, but some may be inconsistent, overly general (e.g., \"Other\"), or repetitive (e.g., slight variations in naming such as \"SEDAN\" and \"Sedan\").\n",
        "- If there are too many categories or lengthy names, they might overlap or be hard to read, especially if the text is not properly formatted.\n",
        "\n",
        "---\n",
        "\n",
        "### 2) **Recommendations to Improve the Bar Chart**  \n",
        "- **Group Similar Categories**: Consolidate similar vehicle types (e.g., \"Sedan\" and \"SEDAN\") to ensure consistent categorization and better data representation.  \n",
        "- **Sort by Relevance**: Ensure categories are sorted by count or alphabetical order for clarity.  \n",
        "- **Adjust X-Axis Formatting**: If names are lengthy, use shorter labels or abbreviations and ensure they are rotated and aligned for readability.  \n",
        "- **Focus on Top Categories**: Consider grouping smaller categories under \"Others\" to make the chart less cluttered and highlight significant trends.  \n",
        "\n",
        "---\n",
        "\n",
        "### 3) **Recommendations for Data Collection/Input**  \n",
        "- **Standardize Data Entry**: Use a controlled vocabulary or predefined dropdown options for vehicle types to avoid inconsistencies in naming (e.g., \"SUV\" vs. \"Sport Utility Vehicle\").  \n",
        "- **Improve Detail**: Ensure contributors provide specific and meaningful vehicle type information instead of generic labels like \"Other.\"  \n",
        "- **Regular Data Cleaning**: Periodically review and clean the dataset to merge duplicates and correct errors in vehicle type classifications.  \n",
        "- **Encourage Completeness**: Implement mandatory fields or better training for data entry staff to reduce missing or vague entries.  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tgft4X1JRP4I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5:**  A DataFrame is a two-dimensional and potentially heterogeneous tabular data structure with labeled axes (rows and columns). DataFrames allow for storing, manipulating, and retrieving data in a structured form, serving as the primary data structure for a multitude of data processing tasks. It is used with Python libraries like pandas.\n",
        "\n",
        "Let's graph the *types* of crashes within this dataset and their frequencies. Begin by aggregating your data, convert to [DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) for simple plotting, and plot.\n",
        "\n"
      ],
      "metadata": {
        "id": "iBDk6ns7rWs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Aggregating data - Complete for Cyclist and Motorist\n",
        "types_of_crashes = {\n",
        "    'Pedestrian Injuries': data['NUMBER OF PEDESTRIANS INJURED'].sum(),\n",
        "    'Cyclist Injuries': data['NUMBER OF CYCLIST INJURED'].sum(),\n",
        "    'Motorist Injuries': data['NUMBER OF MOTORIST INJURED'].sum(),\n",
        "    'Pedestrian Deaths': data['NUMBER OF PEDESTRIANS KILLED'].sum(),\n",
        "    'Cyclist Deaths': data['NUMBER OF CYCLIST KILLED'].sum(),\n",
        "    'Motorist Deaths': data['NUMBER OF MOTORIST KILLED'].sum()\n",
        "}\n",
        "\n",
        "# Converting to DataFrame for easier plotting - use the items function\n",
        "crash_types_df = pd.DataFrame(list(types_of_crashes.items()), columns=['Crash Type', 'Count'])\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(12, 7))\n",
        "sns.barplot(x='Count', y='Crash Type', data=crash_types_df, palette=\"mako\")\n",
        "plt.title('Types of Crashes and Their Frequencies', fontsize=16)\n",
        "plt.xlabel('Count', fontsize=14)\n",
        "plt.ylabel('Type of Crash', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QUalTlGgBPO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TO DO:** Analyze the chart above. What is a recommendation you might make to the Department of Transportation based on this data?\n",
        "\n",
        "\n",
        "1. **Enhance Pedestrian Safety**: Install more crosswalks, improve street lighting, and add traffic-calming measures in high-pedestrian areas to reduce injuries and fatalities.  \n",
        "\n",
        "2. **Expand Cyclist Infrastructure**: Build dedicated bike lanes, maintain existing ones, and educate drivers about sharing the road to protect cyclists.  \n",
        "\n",
        "3. **Improve Motorist Education**: Launch campaigns on safe driving practices and enforce laws against speeding, distracted driving, and impaired driving.  \n",
        "\n",
        "4. **Prioritize Resource Allocation**: Use the data to focus resources on the crash types with the highest frequencies, addressing the most critical safety concerns.  \n",
        "\n",
        "5. **Collaborate for Safety**: Work with local planners, schools, and communities to tailor safety measures to specific high-risk areas.  \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZnWKXa9Nfs-W"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grdrqrdoZPd8"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhRdCZx7ZPd8"
      },
      "source": [
        "##<font color='crimson'> **Milestone #3 - Time Series Analysis**</font>\n",
        "GOAL: The main goal of this milestone is to dive deeper into Time Series Analysis in order to better understand our data's trends over time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IWCx42kgXEa"
      },
      "source": [
        "**Step 1:**\n",
        "\n",
        "Before we jump into Time Series Analysis (TSA), it's important to understand the basics, including Trends, Seasonality, and Residual Components.\n",
        "\n",
        "Review one or more of the following resources and tell us what you learned about TSA!\n",
        "\n",
        "*  [Learn about Time Series patterns here](https://otexts.com/fpp2/tspatterns.html)\n",
        "* [Learn about Time Plots here](https://otexts.com/fpp2/time-plots.html)\n",
        "*[Learn how to decompose Time Series Data into Trend and Seasonality](https://machinelearningmastery.com/decompose-time-series-data-trend-seasonality/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TO DO:** Write 3-5 sentences about TSA.\n",
        "\n",
        "1. **Definition**: Time Series Analysis (TSA) examines data points collected over time to uncover patterns, trends, and temporal relationships.  \n",
        "\n",
        "2. **Key Components**: It includes **trends** (long-term direction), **seasonality** (regular, repeating patterns), and **residuals** (random variations).  \n",
        "\n",
        "3. **Purpose**: TSA helps in understanding historical patterns and predicting future behavior, making it essential for forecasting in various fields.  \n",
        "\n",
        "4. **Decomposition**: Breaking down time series data into trend, seasonality, and residuals provides clearer insights and supports accurate modeling.  \n",
        "\n",
        "5. **Applications**: TSA is widely used in finance, weather forecasting, sales analysis, and resource planning to inform decisions and strategies.  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "b70ap78mf51L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2:** Let's begin by creating a chart that displays the average number of crashes per hour of the day. This will help us understand whether additional factors are contributing to crashes - i.e. rush hour, school dismissal time, night fall, etc."
      ],
      "metadata": {
        "id": "ephb1Ro-xZvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/drive/MyDrive/Motor_Vehicle_Collisions_-_Crashes_20250113.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Convert 'CRASH DATE' and 'CRASH TIME' to datetime\n",
        "data['CRASH DATE'] = pd.to_datetime(data['CRASH DATE'])\n",
        "data['CRASH TIME'] = pd.to_datetime(data['CRASH TIME'], format='%H:%M')\n",
        "\n",
        "# Time of Day Analysis\n",
        "data['Hour of Day'] = data['CRASH TIME'].dt.hour\n",
        "\n",
        "# Group by 'Hour of Day' and calculate the average number of crashes per hour\n",
        "average_crashes_per_hour = data.groupby('Hour of Day').size() / data['Hour of Day'].nunique()\n",
        "\n",
        "# Plot the average number of crashes\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=average_crashes_per_hour.index, y=average_crashes_per_hour.values)\n",
        "plt.title('Average Number of Crashes per Hour of Day')\n",
        "plt.xlabel('Hour of Day')\n",
        "plt.ylabel('Average Number of Crashes')\n",
        "plt.xticks(range(0, 24))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LhCvcjgRBPst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TO DO:** Which time of the day sees the most crashes? Why do you think so?\n",
        "\n",
        "> *  During 16th hour in a day, there are more crashes recorded.\n",
        "\n"
      ],
      "metadata": {
        "id": "54RyJHDngM7G"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWYnmWzltPSd"
      },
      "source": [
        "**Step 3:**\n",
        "Plot a graph to determine how COVID-19 impacted the number of crashes per month, if at all.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'CRASH DATE' to datetime format\n",
        "data['CRASH DATE'] = pd.to_datetime(data['CRASH DATE'])\n",
        "\n",
        "# Group by month and year to get the number of crashes per month\n",
        "monthly_crashes = data.groupby(data['CRASH DATE'].dt.to_period(\"M\")).size()\n",
        "\n",
        "# Plotting the trend over time\n",
        "plt.figure(figsize=(12,6))\n",
        "monthly_crashes.plot()\n",
        "plt.title('Number of Crashes per Month', fontsize=16)\n",
        "plt.xlabel('Date', fontsize=14)\n",
        "plt.ylabel('Number of Crashes', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vnKcvOp8th_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TO DO:** What does your graph tell you about the impact of COVID-19 on the number of crashes per month? Why do you think this occurred?\n",
        "\n",
        "\n",
        "1. **Significant Decline in Crashes:** The graph shows a sharp drop in the number of crashes starting in early 2020, coinciding with the onset of the COVID-19 pandemic.  \n",
        "\n",
        "2. **Reduced Traffic Volume:** Lockdowns, remote work, and school closures significantly decreased the number of vehicles on the road, leading to fewer opportunities for crashes.  \n",
        "\n",
        "3. **Travel Restrictions:** Restrictions on national and international travel further limited vehicle movement and reduced crash occurrences.  \n",
        "\n",
        "4. **Closure of Businesses:** The temporary closure of non-essential businesses and entertainment venues minimized commuting and leisure travel.  \n",
        "\n",
        "5. **Behavioral Changes:** People avoided driving unless absolutely necessary during the pandemic, contributing to the overall reduction in traffic accidents.  \n"
      ],
      "metadata": {
        "id": "II8Q3vM7gXQg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4**: Apply time series decomposition to review trends, seasonality, and residuals. New to time series analysis? Review the [Time Series Flashcard video series](https://youtube.com/playlist?list=PLNs9ZO9jGtUAqd0CNKySksPJJaOqYPMvk&feature=shared) here to learn about trends, components, and further analysis!"
      ],
      "metadata": {
        "id": "1VN3xYo0aOMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "\n",
        "# Count the number of crashes per day, group by CRASH DATE\n",
        "daily_crashes = data.groupby('CRASH DATE').size()\n",
        "\n",
        "# Set plot style\n",
        "sns.set(style=\"darkgrid\")\n",
        "\n",
        "# Plot the daily crashes time series\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.plot(daily_crashes, label='Daily crashes')\n",
        "plt.title('Daily Motor Vehicle Collisions in NYC')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Number of Crashes')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Decompose the time series\n",
        "decomposition = seasonal_decompose(daily_crashes, model='additive', period=365)\n",
        "\n",
        "# Plot the decomposed components\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(15, 12))\n",
        "decomposition.trend.plot(ax=ax1)\n",
        "ax1.set_title('Trend')\n",
        "decomposition.seasonal.plot(ax=ax2)\n",
        "ax2.set_title('Seasonality')\n",
        "decomposition.resid.plot(ax=ax3)\n",
        "ax3.set_title('Residuals')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PFszSQ-J7P20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The visualizations above provide valuable insights into the time series of daily motor vehicle collisions in New York City:\n",
        "\n",
        "1. Time Series Plot: This shows the number of daily crashes over time. You might observe long-term trends, seasonal patterns, or significant outliers.\n",
        "\n",
        "2. Decomposed Components:\n",
        "  \n",
        "    2.1 Trend: This graph shows the long-term trend in the data, which can indicate whether crashes are increasing, decreasing, or stable over time.\n",
        "\n",
        "    2.2 Seasonality: This reveals any regular patterns that repeat over a specific period, such as yearly. It helps identify times of the year with higher or lower crash frequencies.\n",
        "\n",
        "    2.3 Residuals: These are the irregular components that cannot be attributed to the trend or seasonality. They might include random or unpredictable fluctuations."
      ],
      "metadata": {
        "id": "f4-FdmAY7gpu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TO DO:** Based on your *trend graph*, are we seeing an increase or a decrease in crashes between 2014 and 2022?\n",
        "\n",
        "> *  Trend Graph Analysis (2014â€“2022):\n",
        "\n",
        "Based on the trend graph, there appears to be a decrease in the number of crashes between 2014 and 2022. This decline is especially evident after 2020, likely due to the impact of the COVID-19 pandemic, which caused reduced traffic volume and travel restrictions.\n",
        "\n",
        "\n",
        "**TO DO:** Based on your *residual graph*, in what year(s) was there a significant unpredicted fluctuation? Why do you think so?\n",
        "\n",
        "> *  Residual Graph Analysis (Significant Fluctuations):\n",
        "\n",
        "The residual graph shows significant unpredicted fluctuations in 2020. This likely corresponds to the initial outbreak of the COVID-19 pandemic when unexpected changes in travel patterns occurred due to lockdowns and public health measures.\n",
        "Another possible fluctuation might occur around 2021, as traffic patterns began recovering but did not immediately normalize. These fluctuations could reflect the gradual reopening of businesses and changes in travel behaviors."
      ],
      "metadata": {
        "id": "XaC-SbhlglHS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jhsah2fiZPd-"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQLLgAgcZPd_"
      },
      "source": [
        "##<font color='crimson'>**Milestone #4 - Geospatial Analysis**</font>\n",
        "GOAL: The main goal of this milestone is to explore geospatial aspects of the dataset and get comfortable with regional analysis and geospatial visualizations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1_75SdRgXhI"
      },
      "source": [
        "**Step 1:** Before beginning this Milestone, we highly recommend that you review the [NSDC Geospatial Analysis Flashcard Video series](https://www.youtube.com/playlist?list=PLNs9ZO9jGtUAX_2g1-OJp8VkmVum6DqqP) if you are new to Geospatial Analysis!\n",
        "\n",
        "Let's build a bar chart to compare and analyze the number of crashes across the five boroughs: Brooklyn (also known as Kings County), Queens, Manhattan, Bronx, and Staten Island."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Plot a bar chart to compare the number of crashes that occurred in each of the five boroughs.\n",
        "\n",
        "# Set style\n",
        "sns.set_style(\"whitegrid\")\n",
        "# Plotting the distribution of crashes by borough\n",
        "plt.figure(figsize=(10, 6))\n",
        "# Find the count of unique values of BOROUGHS. Hint: Use value_count function.\n",
        "borough_count = data['BOROUGH'].value_counts()\n",
        "sns.barplot(x=borough_count.index, y=borough_count.values, palette=\"viridis\")\n",
        "plt.title('Distribution of Crashes by Borough', fontsize=16)\n",
        "plt.xlabel('Borough', fontsize=14)\n",
        "plt.ylabel('Number of Crashes', fontsize=14)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "STDfC8VDBAjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TO DO:** Which borough has the highest number of crashes? Which borough has the lowest?\n",
        "\n",
        "> * Highest: Brooklyn, with approximately 450,000 crashes\n",
        "> * Lowest: Staten Island, with approximately 60,000 crashes\n",
        "\n",
        "\n",
        "**TO DO:** Are there any reasons that you think a certain borough has a higher or lower number of crashes? What are some factors that may be causing this?\n",
        "\n",
        "> *  ## Factors Influencing Crash Distribution-\n",
        "\n",
        "1. Population Density and Size : Brooklyn's high crash numbers likely stem from it being the most populous borough with over 2.5 million residents, leading to more vehicles and traffic interactions. Conversely, Staten Island's lower numbers correlate with its smaller population and more suburban character.\n",
        "\n",
        "2. Traffic Patterns : Brooklyn and Queens show higher crash rates due to their roles as major transit corridors between Manhattan and Long Island. Brooklyn's complex street grid and numerous intersections create more potential conflict points for vehicles. Staten Island's more spread-out, suburban layout and fewer major arterial roads contribute to fewer crashes.\n",
        "\n",
        "3. Commercial Activity : The higher crash rates in Brooklyn, Queens, and Manhattan likely reflect their intense commercial activity, resulting in:\n",
        "       -Higher concentration of delivery vehicles\n",
        "       -More frequent parking maneuvers\n",
        "       -Greater mix of vehicle types (trucks, cars, taxis)\n",
        "\n",
        "The distribution pattern suggests a clear correlation between urban density, commercial activity, and crash frequency, with the most urbanized boroughs experiencing significantly more crashes than less dense areas."
      ],
      "metadata": {
        "id": "N3qjnEBHhBKU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRgTHDTk-0vz"
      },
      "source": [
        "**Step 2:** Heatmaps are graphical representations that use color coding to represent different values and variables. Let's leverage a heatmap to determine the most dangerous intersections in the dataset. (**Note: the below cell may take a few minutes to run**)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Create a heatmap leveraging the latitude and longitude variables to determine where the most crashes are occurring\n",
        "from folium.plugins import HeatMap\n",
        "\n",
        "# Drop rows with missing latitude and longitude values\n",
        "data_geo = data.dropna(subset=['LATITUDE', 'LONGITUDE'])\n",
        "\n",
        "# Create a base map\n",
        "m = folium.Map(location=[40.730610, -73.935242], zoom_start=10)  # Centered around NYC\n",
        "\n",
        "# Create a heatmap\n",
        "heat_data = [[row['LATITUDE'], row['LONGITUDE']] for index, row in data_geo.iterrows()]\n",
        "HeatMap(heat_data, radius=8, max_zoom=13).add_to(m)\n",
        "\n",
        "m.save(\"Heatmap.html\")"
      ],
      "metadata": {
        "id": "5E4EMhdfDwE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TO DO:** On the left side of your screen, you will see an icon that represents a folder or a file. Click on that icon to find the file titled \"Heatmap.html\". Click on the three dots next to your file and download your heatmap! Open the file once downloaded to see your creation.\n",
        "\n",
        "When looking at your heatmap, where do you see a concentration of crashes?\n",
        "\n",
        "1.Manhattan Core\n",
        "- Most intense concentration in Midtown and Lower Manhattan\n",
        "- Strong density along the entire length of Manhattan island\n",
        "- Particularly heavy around the I-95 corridor\n",
        "\n",
        "2.Queens-Brooklyn Corridor\n",
        "- Dense clustering along the Queens-Brooklyn border\n",
        "- Heavy concentration extending through central Queens\n",
        "- Notable hotspot around Jamaica and Queens Boulevard\n",
        "\n"
      ],
      "metadata": {
        "id": "M0JswfvzRqGD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3:** Next, we will begin \"Severity Mapping.\" We'll plot crashes on the map and code them based on severity, distinguishing between crashes that resulted in injuries and those that led to fatalities. This will give us a visual representation of where severe crashes tend to occur. </br>\n",
        "\n",
        "You may initially want to code these incidents by using different colors, but it's important to think about your map and how accessible it is. Will a color-coded map be easy to read for everyone? Let's make a map that's inclusive for people with color blindness by also creating differently-shaped markers (squares, circles, and triangles) for crashes, injuries, and fatalities."
      ],
      "metadata": {
        "id": "33soqCswFQSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Continue building your heatmap\n",
        "# Sample a subset of the data for visualization\n",
        "sample_data_severity = data_geo.sample(n=1000, random_state=42)\n",
        "\n",
        "# Create a base map\n",
        "m_severity = folium.Map(location=[40.730610, -73.935242], zoom_start=10)\n",
        "\n",
        "# Add crashes to the map with color coding and shape coding based on severity\n",
        "for index, row in sample_data_severity.iterrows():\n",
        "    if row['NUMBER OF PERSONS KILLED'] > 0:\n",
        "        color = \"red\"  # Fatalities\n",
        "\n",
        "        folium.features.RegularPolygonMarker(\n",
        "          location=[row['LATITUDE'], row['LONGITUDE']],\n",
        "          number_of_sides=3,\n",
        "          radius=5,\n",
        "          gradient = False,\n",
        "          color=color,\n",
        "          fill=True,\n",
        "          fill_color=color\n",
        "        ).add_to(m_severity)\n",
        "\n",
        "\n",
        "    elif row['NUMBER OF PERSONS INJURED'] > 0:\n",
        "        color = \"blue\"  # Injuries\n",
        "        folium.CircleMarker(\n",
        "          location=[row['LATITUDE'], row['LONGITUDE']],\n",
        "          radius=5,\n",
        "          color=color,\n",
        "          fill=True,\n",
        "          fill_color=color\n",
        "       ).add_to(m_severity)\n",
        "    else:\n",
        "        color = \"gray\"  # No injuries or fatalities\n",
        "        folium.features.RegularPolygonMarker(\n",
        "          location=[row['LATITUDE'], row['LONGITUDE']],\n",
        "          number_of_sides=4,\n",
        "          radius=5,\n",
        "          gradient = False,\n",
        "          color=color,\n",
        "          fill=True,\n",
        "          fill_color=color\n",
        "        ).add_to(m_severity)\n",
        "m_severity.save(\"severity.html\")"
      ],
      "metadata": {
        "id": "lnziyy5KExsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TO DO:** On the left side of your screen, you will see an icon that represents a folder or a file. Follow the same steps as above to download the \"Severity.html\" file.\n",
        "\n",
        "**TO DO:** Which intersection(s) seem to be the most dangerous?\n",
        "\n",
        "> *  Looking at this severity map visualization of NYC crashes, we can say that the most dangerous intersection appears to be the Times Square area (Broadway/7th Avenue intersection), as evidenced by the highest density of blue circles (injury crashes) and gray diamonds (non-injury crashes), with some red triangles (fatalities) in the vicinity. This area combines heavy vehicular traffic with intense pedestrian activity, creating numerous conflict points for potential crashes.\n",
        "\n"
      ],
      "metadata": {
        "id": "mFWXrM6UhYuB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sKFTgJ0gSZd"
      },
      "source": [
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##<font color='crimson'>  **Milestone #5 - Self-Guided Research Question**</font>\n",
        "GOAL: In this Milestone, you will be prompted to take what youâ€™ve learned throughout this project, build your own research question, and create a visualization(s) or model(s) to support your research goals.\n"
      ],
      "metadata": {
        "id": "G3WwifeWQ-Ka"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You may create your visualization(s) in this Colab Notebook, or in Excel, Tableau, PowerBI, etc. Choose whichever medium you are most comfortable with! Be creative!\n",
        "\n",
        "For participants who are comfortable with advanced data science techniques, we welcome you to leverage additional datasets, if desired. We highly recommend using pre-cleaned datasets from open data sources, like Kaggle.com.\n",
        "\n",
        "If you have any questions or get stuck, please email nsdc@nebigdatahub.org with your queries. We're here to help!"
      ],
      "metadata": {
        "id": "HjwN2zRsrePc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1:** Review the dataset(s) that you will be using. As you explore, [consider the research question you want to answer](https://libraries.indiana.edu/sites/default/files/Develop_a_Research_Question.pdf)! Additionally, think about [who you are telling your data's story to](https://hbr.org/2013/04/how-to-tell-a-story-with-data). Your final audience may contain a group of transportation professionals, data scientists, peers, and the general public. Think about how would you frame your analysis differently for each of these groups."
      ],
      "metadata": {
        "id": "gCLd4lziVW9R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TO DO:** List one or more research questions here that you are considering.\n",
        "\n",
        "> *  Based on the NYC crash data analysis we've performed, here are compelling research questions worth investigating:\n",
        "\n",
        "## Safety and Infrastructure Questions\n",
        "\n",
        "**Temporal Patterns**\n",
        "- How do crash patterns vary by time of day and day of week, and can this inform targeted safety interventions?\n",
        "- Is there a correlation between weather conditions and crash severity?\n",
        "\n",
        "**Location-Based Analysis**\n",
        "- What characteristics do high-crash intersections share, and how can this inform infrastructure improvements?\n",
        "- Are crashes more frequent near specific types of facilities (schools, shopping centers, entertainment venues)?\n",
        "\n",
        "## Demographic and Social Impact\n",
        "\n",
        "**Community Impact**\n",
        "- Is there a correlation between neighborhood demographics and crash frequency/severity?\n",
        "- How do crash patterns differ between residential and commercial areas?\n",
        "\n",
        "**Transportation Equity**\n",
        "- Are certain communities disproportionately affected by traffic crashes?\n",
        "- How does access to public transportation correlate with crash rates?\n",
        "\n",
        "## Policy and Prevention\n",
        "\n",
        "**Intervention Effectiveness**\n",
        "- What impact have previous safety interventions had on crash rates in specific locations?\n",
        "- Can we identify predictive factors that could help prevent future crashes?\n",
        "\n",
        "These questions aim to provide actionable insights for transportation planners, policymakers, and community stakeholders while addressing both immediate safety concerns and longer-term systemic issues."
      ],
      "metadata": {
        "id": "0gpR0CpCh6b6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2:** Now, think about what type of analysis you'd like to complete. Are you interested in looking at time series forecasting? Do you have additional maps in mind that you'd like to create? Is there a certain zip code or region you'd like to dive deeper into?\n",
        "\n",
        "If you happen to be stuck, here are some examples that you can use or can guide you in choosing your research question!\n",
        "\n",
        "**Examples:**\n",
        "- How many crashes, injuries, and/or fatalies occurred in a zip code of interest?\n",
        "- Which zip code sees the highest amount of crashes and what recommendations can you offer to help that community? Is it an underserved community?\n",
        "- Do more crashes occur in underrepresented communities? Support your conclusion.\n",
        "- Which day of the week sees the most crashes, injuries, and/or fatalities? (Hint: use the same method we used when we were analyzing the average number of crashes at different times of the day!)\n",
        "- Does the geometric features of an intersection (90 degree intersection vs skewed intersection) affect the number of crashes that occur?\n",
        "\n",
        "Be creative and think outside the box!\n",
        "\n",
        "ANSWER:\n",
        "\n",
        "Based on the dataset and previous analyses, here are several compelling analytical approaches worth pursuing:\n",
        "\n",
        "## Time-Based Analysis\n",
        "\n",
        "**Seasonal Patterns**\n",
        "- Analyze crash patterns across different seasons to identify if certain weather conditions or daylight patterns affect crash rates\n",
        "- Compare weekday vs weekend crash distributions to understand how traffic patterns influence safety\n",
        "\n",
        "**Peak Hours Investigation**\n",
        "- Examine the relationship between rush hour traffic and crash severity\n",
        "- Study late-night accident patterns and their correlation with factors like lighting conditions\n",
        "\n",
        "## Geographic Analysis\n",
        "\n",
        "**Neighborhood Equity Study**\n",
        "- Compare crash rates between different socioeconomic areas\n",
        "- Analyze the relationship between crash frequency and access to public transportation\n",
        "- Investigate if there's a correlation between crash rates and infrastructure investment in different neighborhoods\n",
        "\n",
        "## Infrastructure Impact\n",
        "\n",
        "**Intersection Design Analysis**\n",
        "- Compare crash rates at different types of intersections (T-junctions, 4-way, roundabouts)\n",
        "- Study the impact of recent infrastructure improvements on crash rates\n",
        "- Analyze the effectiveness of traffic calming measures in high-risk areas\n",
        "\n",
        "## Vulnerable Road Users\n",
        "\n",
        "**Pedestrian and Cyclist Safety**\n",
        "- Map locations with high pedestrian/cyclist involvement\n",
        "- Analyze the relationship between bike lane presence and crash rates\n",
        "- Study the impact of school zones on crash patterns\n",
        "\n",
        "This analysis would focus on creating actionable insights for transportation planners and policymakers while addressing equity concerns and public safety improvements.\n",
        "\n"
      ],
      "metadata": {
        "id": "cjYJKXVtOnQ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3:** Now that you've decided on your transportation research question, [explore the various types of visualizations you can create to support your research](https://datavizcatalogue.com/). You may create visualizations in this Google Colab notebook, Excel, R, SQL, PowerBI, Tableau, etc. Choose a program you are comfortable with!\n",
        "\n",
        "You may also choose to build a model or leverage a different data science technique based on your experience level.\n",
        "\n",
        "\n",
        "ANSWER:\n",
        "\n",
        "Based on the research questions proposed, recommended visualization approaches:\n",
        "\n",
        "## Temporal Analysis Visualizations\n",
        "\n",
        "**Time-Based Patterns**\n",
        "- Heat calendar showing crash density by day of week and hour\n",
        "- Line charts tracking crash frequency across seasons\n",
        "- Stacked bar charts comparing weekday vs weekend severity patterns\n",
        "\n",
        "## Geographic Visualizations\n",
        "\n",
        "**Interactive Maps**\n",
        "- Choropleth maps showing crash density by neighborhood\n",
        "- Point-density maps with toggle layers for different severity levels\n",
        "- Buffer analysis maps around schools and transit stations\n",
        "\n",
        "## Demographic Analysis\n",
        "\n",
        "**Socioeconomic Correlations**\n",
        "- Scatter plots comparing median income vs crash rates\n",
        "- Bar charts showing crash rates by neighborhood demographics\n",
        "- Heat maps overlaying infrastructure investment with crash hotspots\n",
        "\n",
        "## Infrastructure Impact\n",
        "\n",
        "**Safety Analysis**\n",
        "- Before/after comparison charts for areas with recent improvements\n",
        "- Box plots comparing crash rates by intersection type\n",
        "- Violin plots showing severity distribution by road type\n",
        "\n",
        "## Implementation Tools\n",
        "\n",
        "**Technical Options**\n",
        "- Python with Folium for interactive mapping\n",
        "- Plotly for dynamic time series visualization\n",
        "- Seaborn for statistical relationship plots\n",
        "- GeoPandas for spatial analysis\n",
        "\n",
        "The visualizations should be interactive where possible, allowing stakeholders to explore different aspects of the data and draw their own insights while maintaining accessibility for all users.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HZ2b-2yiUT0w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4:** Consider the **accessibility** of the graphs, charts, maps, or models you are interested in building. Use the tools below to learn more!\n",
        "* How does your visualization appear to people [who may not be able to distinguish between muted colors or see your chart at all?](https://chartability.fizz.studio/)\n",
        "*[Color Contrast Checker](https://policyviz.com/2022/11/01/color-contrast-checker-in-excel/)\n",
        "*[SAS Graphics Accelerator](https://support.sas.com/software/products/graphics-accelerator/index.html)\n",
        "*[TwoTone Data Sonification Tool](https://twotone.io/about/)\n",
        "*[Making Visual Studio Accessible](https://code.visualstudio.com/docs/editor/accessibility)"
      ],
      "metadata": {
        "id": "XwJzrPP1Shfl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make visualizations more inclusive for people with color blindness, you can choose a color palette that is colorblind-friendly. `Seaborn`, a Python visualization library, provides several palettes that are designed to be perceptible by those with color vision deficiencies. Seaborn's `cubehelix` palette is a good choice, as it was designed specifically with color blindness in mind.\n",
        "## Visual Accessibility Considerations\n",
        "\n",
        "**Color and Contrast**\n",
        "- Use high contrast color combinations with a ratio of at least 4.5:1\n",
        "- Avoid problematic color combinations like red/green, blue/grey, and blue/purple that are difficult for colorblind users to distinguish\n",
        "- Implement patterns or textures alongside colors to differentiate data points\n",
        "\n",
        "## Alternative Access Methods\n",
        "\n",
        "**Screen Reader Compatibility**\n",
        "- Include descriptive alt text for all charts and visual elements\n",
        "- Provide semantic headings and clear data labels\n",
        "- Add text summaries explaining key trends and insights\n",
        "\n",
        "**Data Sonification**\n",
        "- TwoTone tool can convert data into audio formats using different instruments and tempos\n",
        "- Sound representation helps visually impaired users identify patterns and trends in the data\n",
        "- Allows for multi-modal data experience with both visual and audio components\n",
        "\n",
        "## Best Practices\n",
        "\n",
        "**Direct Labeling**\n",
        "- Label data points directly instead of relying on legends\n",
        "- Use clear, readable fonts with sufficient size\n",
        "- Ensure adequate spacing between elements\n",
        "\n",
        "**Interactive Elements**\n",
        "- Make all interactive features keyboard-accessible\n",
        "- Include visible focus indicators for keyboard navigation\n",
        "- Provide clear instructions for using any interactive features\n",
        "\n",
        "**Supporting Content**\n",
        "- Include accessible data tables alongside visualizations\n",
        "- Provide downloadable raw data when possible\n",
        "- Add comprehensive text descriptions of key findings\n",
        "\n",
        "These accessibility considerations ensure that data visualizations are usable by all audiences, regardless of visual ability or assistive technology needs.\n"
      ],
      "metadata": {
        "id": "Gol18r4mZL75"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5:** Begin your research! Give yourself plenty of time to build your visualization or model. If you have any questions along the way, please email nsdc@nebigdatahub.org or write a message in the #[tdsp-community Slack Channel](https://join.slack.com/t/nsdcorps/shared_invite/zt-1h64t1e2p-La0AgU_HhymWUEGFQEcb3w)."
      ],
      "metadata": {
        "id": "TVO8yKiiXX4L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TO DO:** List the research question(s) you've chosen and why! Maybe you chose this question because it can help a community of interest or because it is similar to research you've completed in a class setting. Share your thoughts below.\n",
        "\n",
        "> *  Based on the NYC crash data, I propose investigating:\n",
        "\n",
        "## Primary Research Question-\n",
        "\"How do crash patterns and severity vary across different times of day and days of the week, and what is their relationship with neighborhood demographics?\"\n",
        "\n",
        "## Supporting Questions\n",
        "- Are crashes more frequent or severe in lower-income neighborhoods?\n",
        "- Do certain days or times show higher crash severity patterns?\n",
        "- Is there a correlation between public transit access and crash frequency?\n",
        "\n",
        "\n",
        "This research could directly benefit communities by identifying specific time periods and locations where enhanced safety measures are most needed, while also addressing potential systemic inequities in traffic safety."
      ],
      "metadata": {
        "id": "-3M7OW67iFQO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TO DO:** Build a visualization, model, or use other statistical methods to gain insights into your data and to support your research question."
      ],
      "metadata": {
        "id": "LreRzzMPiQgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TO DO: Begin creating here!\n",
        "\n",
        "# Convert date and create day of week\n",
        "data['CRASH DATE'] = pd.to_datetime(data['CRASH DATE'])\n",
        "data['day_of_week'] = data['CRASH DATE'].dt.day_name()\n",
        "\n",
        "# Create temporal analysis\n",
        "temporal_data = data.groupby(['day_of_week', 'Hour of Day']).size().reset_index(name='count')\n",
        "\n",
        "# Create the heatmap\n",
        "temporal_heatmap = temporal_data.pivot_table(\n",
        "    index='day_of_week',\n",
        "    columns='Hour of Day',\n",
        "    values='count',\n",
        "    aggfunc='sum'\n",
        ")\n",
        "\n",
        "# Define the correct order for days of the week\n",
        "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
        "\n",
        "# Reorder the index of the heatmap\n",
        "temporal_heatmap = temporal_heatmap.reindex(day_order)\n",
        "\n",
        "# Visualize the updated heatmap\n",
        "plt.figure(figsize=(25, 10))\n",
        "sns.heatmap(temporal_heatmap, cmap='YlOrRd', annot=True, fmt='g')\n",
        "plt.title('Crash Frequency by Day and Hour')\n",
        "plt.xlabel('Hour of Day')\n",
        "plt.ylabel('Day of Week')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ny_MoMMAX5xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "bXADl1pITV8u"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUc6Ziyr91Ni"
      },
      "source": [
        "##<font color='crimson'>**Milestone #6 - Virtual Poster Board Creation: Data Storytelling**</font>\n",
        "\n",
        "GOAL: The main goal of this milestone is to create a one page, virtual poster board to portray your research findings and recommendations! Your poster may be shared with the Department of Transportation and Federal Highway Authority."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Within your poster, summarize your research question, your reasoning for selecting your data visualization or model choices, and key insights from your data analysis. You may also wish to include your outstanding research questions that could not be answered by the dataset and why.\n",
        "\n",
        "**Be sure to answer the following on your virtual poster board:** Based on your research insights, what recommendations would you share with the Department of Transportation and Federal Highway Authority to make roads safer for vulnerable road users? Why?\n",
        "\n",
        "**Additionally, be sure to cite all relevant sources that you referred to throughout this project on your poster board (MLA or APA citation preferred). List acknowlegdments if you received any support from mentors, professors, professionals, etc. throughout your journey.**"
      ],
      "metadata": {
        "id": "dSJWPQririQr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Q6F_EKh97En"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        " Please use the following resources to get started!\n",
        "\n",
        "\n",
        "*   [Virtual Poster Board Template](https://nebigdatahub.org/wp-content/uploads/2024/01/Copy-of-dsi-poster.ppt-48-Ã—-36-in.pdf) - Your one-page, virtual poster may be created in PowerPoint, Google Slides, Canva, etc. Choose what you are most comfortable with!\n",
        "* [ Data Storytelling: How to Effectively Tell a Story with Data](https://online.hbs.edu/blog/post/data-storytelling)\n",
        "\n",
        "* [  Consider how your visualization(s) might appear to people with varying abilities ](https://chartability.fizz.studio/)\n",
        "*  [Understand your audience for an optimal presentation](https://hbr.org/2013/04/how-to-tell-a-story-with-data)\n",
        "\n",
        "\n",
        "Once completed, please use the [following TDSP Submission Form](https://docs.google.com/forms/d/e/1FAIpQLSeX1OSHj58EQs4ypFEPB_SH3OpWZeo67yU0WWOPVSqYtDrpWg/viewform) to share your Google Colab Notebook and your one-page, virtual project poster with the NSDC HQ Team.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vnt82SSPBD7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "83jaoBKTA8Ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mL1tooesB5CW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4V1-YsD695Bc"
      },
      "source": [
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UT8Rpdt4ZPeA"
      },
      "source": [
        "## ðŸš—<font color='crimson'> **Thank you for completing the project!**</font> ðŸš—\n",
        "\n",
        "We are one step closer to making roads safer for all. [Please submit all materials to the NSDC HQ team](https://docs.google.com/forms/d/e/1FAIpQLSeX1OSHj58EQs4ypFEPB_SH3OpWZeo67yU0WWOPVSqYtDrpWg/viewform) in order to receive a certificate of completion. Do reach out to us if you have any questions or concerns. We are here to help you learn and grow.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "58fcf84e0ebbaad2b6cc744ed9d48691de4e147b5be28c3707516d96647d7374"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}